---
title: "HDT7 - RNA"
author: "Andres Quinto, Mirka Monzon, Oscar De Leon"
date: "3/05/2022"
output: 
  html_document:
    code_folding: hide
    word_document: default
    pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r echo=FALSE, message=FALSE, warning=FALSE}
library(caret)
library(nnet)
install.packages("RWeka")
library(RWeka)
library(neural)
library(dummy)
library(neuralnet)
library(PerformanceAnalytics)
library(readr)
library(keras)
library(plotly)
library(neuralnet)
library(MASS)
library(tidyverse)
```


# Hoja de Trabajo No. 7.2: Redes neuronales

En esta hoja de trabajo se busca poder clasificar una casa según su precio de venta, dividiendoló en 3 grupos; económicas, intermedias y caras. con el fin de poder realizar esta predicción se utilizará redes neuronales para evaluar cuál método ofrece el mejor resultado. Los algoritmos de RNA son capaces de aprender modicándose automáticamente a sí mismos y automatizando sus funciones, son bastante complejos, pero esto permite que la predicción sea certera.

Primero es necesario cargar los datos, colocar los rangos y realizar el corte para tener un conjunto de entrenamiento y otro de prueba

```{r echo=FALSE, message=FALSE, warning=FALSE}
datosCasas <- read.csv("train.csv")

porciento <- 70/100
set.seed(123)
datosCasas$clasificacion <- ifelse(datosCasas$SalePrice <= 251000, "Economicas", ifelse(datosCasas$SalePrice <= 538000, "Intermedias", ifelse(datosCasas$SalePrice <= 755000, "Caras")))
datosCasas$y <- factor(datosCasas$clasificacion)
datos <- datosCasas[,c(2,4,18,19,20,21,27,35,37,38,39,44,45,46,47,48,49,50,51,52,53,55,57,60,62,63,67,68,69,70,71,72,76,77,78,81,83)]
datos <- datos[,colSums(is.na(datos))==0]
trainRowsNumber<-sample(nrow(datos),porciento*nrow(datos))
trainRowsNumber2<-sample(nrow(datos),45/100*nrow(datos))
train<-datos[trainRowsNumber,]
test<-datos[-trainRowsNumber,]
```

Para poder clasificar una casa como económica, inermedia y cara se utilizarán 2 métodos de redes neuronales con distinta topología para poder comparar resultados e identificar difenrencias.
Primero se utilizará el modelo de redes neuronales por nnet:

## Modelo con redes neuronales por nnet:

```{r nnet clasificación, echo=FALSE, message=FALSE, warning=FALSE}
modelo.nn2 <- nnet(datos$y~.,data = datos,subset = trainRowsNumber, size=2, rang=0.1,
                   decay=5e-4, maxit=200) 
prediccion2 <- as.data.frame(predict(modelo.nn2, newdata = test[,1:33]))
columnaMasAlta<-apply(prediccion2, 1, function(x) colnames(prediccion2)[which.max(x)])
test$prediccion2<-columnaMasAlta 
cfm<-confusionMatrix(as.factor(test$prediccion2),test$y)
cfm
```

Utilizando redes neuronales por nnet se obtuvo un porcentaje de acuero de casi 86% en donde, si se observa la matriz de confusión, hubo una equivocación de 2 casas caras y 60 casas intermedias, que a pesar de mostrar un buen porcentaje de predicción, parece ser un número significativo de equivocaciones, cabe mencionar que el modelo solo predijo que las casas eran económicas.

Ahora se utilizará el modelo por RWEKA

## Modelo con redes neuronales por RWeka

```{r Rweka clasificación, echo=FALSE, message=FALSE, warning=FALSE}
NB <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
NB 
WOW(NB)
nnodos='33'
modelo.bp<-NB(datos$y~., data=datos,subset = trainRowsNumber, control=Weka_control(H=nnodos, N=1000, G=TRUE), options=NULL)
test$prediccionWeka<-predict(modelo.bp, newdata = test[,1:33])
cfmWeka<-confusionMatrix(test$prediccionWeka,test$y)
cfmWeka
```
Con un modelo de redes neuronales por RWEKA con 32 nodos, se ha obtenido un porcenaje de 97% de acierto. En este modelo, como se puede ver en la matriz de confusión, se han clasificado incorrectamente 6 casas económicas y 8 casas intermedias, por lo que su capacidad de predicción parece ser muy buena. Cabe mencionar que a diferencia del anterior (nnet) el tiempo de entrenamiento fue un poco más tardado, pero esto se puede ver reflejado en un aumento en el porcentaje de acierto.

En comparación de los dos métodos anteriores con distintas topologías, se puede ver una mejora en la red realizada por RWEKA, como dicho en el análisis de nnet, se notó que la predicción se limitó principalmente a clasificar las casas como económicas, parece que el algoritmo aprendió patrones que no se pueden generalizar tanto, lo cual se vio evidenciado en el resultado de clasificación, por el otro lado, por RWEKA se puede observar que ya no sucede este mismo, ahora la predicción clasifica correctamente más casas, por lo que el porcentaje de error disminuye considerablemente.



```{r echo=FALSE, message=FALSE, warning=FALSE}
datos$clasificacion <- factor(datos$y)
datos$y <- factor(datos$SalePrice)
drop <- c("SalePrice")
drop2 <- c("clasificacion")
drop3 <- c("prediccion2")
  
datos = datos[,!(names(datos) %in% drop)]
datos = datos[,!(names(datos) %in% drop2)]
train$clasificacion <- factor(train$y)
train$y <- factor(train$SalePrice)
train = train[,!(names(train) %in% drop)]
train = train[,!(names(train) %in% drop2)]
test$clasificacion <- factor(test$y)
test$y <- factor(test$SalePrice)
test = test[,!(names(test) %in% drop)]
test = test[,!(names(test) %in% drop2)]
test = test[,!(names(test) %in% drop3)]
```


```{r nnet clasificación, echo=FALSE, message=FALSE, warning=FALSE}
modelo.nn3 <- nnet(train$y~.,data = train, subset = trainRowsNumber2, size=2, rang=0.1,
                   decay=5e-4, maxit=200) 
prediccion3 <- as.data.frame(predict(modelo.nn3, newdata = test[,1:33]))
columnaMasAlta<-apply(prediccion3, 1, function(x) colnames(prediccion3)[which.max(x)])
test$prediccion3<-columnaMasAlta 
#str(test)
cfm<-confusionMatrix(as.factor(test$prediccion3),test$y)
cfm
```
(Se tuvo que reducir el porcentaje de entrenamiento de modelo debido a limitantes de la libreria)

Como se puede observar en los resultados la precision de la red neuronal nnet es muy baja obteniendo tan solo 0.0046, su capacidad para predecir precios de venta fue mala. 


```{r Rweka clasificación, echo=FALSE, message=FALSE, warning=FALSE}
NB2 <- make_Weka_classifier("weka/classifiers/functions/MultilayerPerceptron")
NB2 
WOW(NB2)
nnodos='33'
modelo.bp2<-NB2(datos$y~., data=datos,subset = trainRowsNumber2, control=Weka_control(H=nnodos, N=1000, G=TRUE), options=NULL)
test$prediccionWeka2<-predict(modelo.bp2, newdata = test[,1:33])
cfmWeka2<-confusionMatrix(test$prediccionWeka2,test$y)
cfmWeka2
```

La precision de RWeka en comparacion con nnet obtiene un rendimiento mayor, aumentando su precision y capacidad de realizar predicciones de precio de venta. 

En general, el modelo realizado empleando RWeka tuvo un mejor desempeño respecto al objetivo de realizar predicciones de precios de venta de casas. Debido a la reduccion de subset de aprendizaje, la precision en ambos modelos se vio afectada, sin embargo RWeka tuvo mayor capacidad de adaptacion con la limitante. 


## Comparacion modelo RNA con algoritmos anteriores

```{r echo=FALSE, message=FALSE, warning=FALSE}
modelos_prediccion <- c("Naive Bayes", "Regresion Lineal", "Arbol de Clasificacion", "SVM", "Neural Net(Caret)", "Neural Net(NNet)")
accuracies <- c(76.69, 70.05, 73.61, 83.99, 85.85, 85.61)
comparacion_prediccion <- data.frame(modelos_prediccion, accuracies)

fig_1 <- plot_ly(comparacion_prediccion, x = ~modelos_prediccion, y = ~accuracies, type = 'bar', text = paste(signif(accuracies,digits = 4),"%"), textposition = 'auto', name = '')
fig_1<- fig_1 %>% layout(title="Precision del modelo vs Modelo Aplicado",yaxis = list(title = 'Accuracy(%)'),xaxis = list(title = 'Modelo Aplicado'), barmode = 'group')
fig_1
```
Como podemos ver en la grafica anteriormente presentada, tenemos varios algoritmo, donde se comparo por su accurancy, y en el primer puesto se obtuvo Neurnal Net(caret) y muy de cerca le siguen Neurnal Net(NNET) y SVM.
Ahora sobre los algortimos para clasificar, tambien podemos ver algunos en la misma grafica anterior, como el arbol de clasificacio, el cual tiene un accurancy de 73.61% el cual es un porcentaje bueno pero no tanto si lo comparamos con las redes neuronales.

## Resultados y explicaciones 

Al comparar los resultados obtenidos con los diferentes modelos de clasificacion usando redes neuronales, podemos ver que RNA realizadas por la librería de Caret fueron las más efectivas con un 85.85% de precision y con una diferencia de 0.24% respecto a las predicciones por la librería NNet con una presicion de 85.61%. No se puede determinar qué modelo es el mejor, pero sí qué modelo nos dio mejores resultados, y fue el modelo de redes neuronales con Caret. Siendo este el modelo más efectivo, hablando del tiempo de ejecución podemos decir que ambos algoritmos demoraron lo mismo. Ahora en comparación con los otros modelos que se realizaron en hojas de trabajo anteriores, podemos también determinar que en esta hoja de trabajo obtuvo los índices de accuracy más altos a los que se ha llegado. Asimismo, se obtuvieron los tiempos de ejecucion mas cortos. 
En conclusión las redes neuronales fueron mucho más efectivas para realizar la prediccion. Aunque como se menciono anteriormente, no podemos decir con certeza si los otros algoritmos no pueden mejorar su efectividad utilizando otros metodos o mejoras en su algoritmo.

Por ultimo, al comparar los resultados obtenidos con los modelos de clasificacion usando redes neuronales para estimar la variable de respuesta "SalePrice" podemos ver que el modelo de red neuronal realizado con Caret es mas "efectivo" 
